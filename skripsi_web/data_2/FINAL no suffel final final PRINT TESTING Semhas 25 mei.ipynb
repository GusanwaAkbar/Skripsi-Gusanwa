{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f09496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 07:25:49.218614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-25 07:25:49.218653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19750e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70c45901",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68652783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(\"rumus + data skripsi angka polos jarak dan visibilitas 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d56b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data_with_ratio(ratio):\n",
    "    # Membaca data dari file CSV menggunakan Pandas\n",
    "    data = pd.read_csv(\"rumus + data skripsi angka polos jarak dan visibilitas 2.csv\")\n",
    "    data = data[[\"Peruntukan\",\"Jarak_pusat_kota2\",\"Visibilitas\",\"Bangunan\",\"Luas\"]]\n",
    "\n",
    "    # Memisahkan data berdasarkan kolom \"Peruntukan\"\n",
    "    peruntukan_data = {}\n",
    "    for label in ['Sawah', 'Perumahan', 'Taman', 'Ruko', 'Kantor', 'Pasar']:\n",
    "        peruntukan_data[label] = data[data['Peruntukan'] == label]\n",
    "\n",
    "    # Memeriksa setiap label untuk memastikan ada minimal satu data\n",
    "    for label in peruntukan_data:\n",
    "        if peruntukan_data[label].empty:\n",
    "            print(f\"Label {label} tidak memiliki data yang mewakili\")\n",
    "            return None\n",
    "\n",
    "    # Menginisialisasi data pelatihan dan pengujian\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    # Memisahkan data pelatihan dan pengujian berdasarkan rasio\n",
    "    for label in peruntukan_data:\n",
    "        label_train, label_test = train_test_split(peruntukan_data[label], test_size=ratio, random_state=42, shuffle = False)\n",
    "        train_data.append(label_train)\n",
    "        test_data.append(label_test)\n",
    "\n",
    "    # Mengembalikan data pelatihan dan pengujian\n",
    "    train_data\n",
    "    test_data\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850c28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10686067",
   "metadata": {},
   "source": [
    "# Data visualisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357eabc",
   "metadata": {},
   "source": [
    "# Change categorical to number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47f89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_categorical_to_number(data):\n",
    "    \n",
    "    data = data\n",
    "    \n",
    " \n",
    "    ####\n",
    "    ####\n",
    "\n",
    "    condition = [  data.Visibilitas == \"Strategis\",\n",
    "                 data.Visibilitas == \"Sedang\",\n",
    "                  data.Visibilitas == \"Kurang\",\n",
    "    ]\n",
    "\n",
    "    value = [3,2,1]\n",
    "\n",
    "    data.Visibilitas = np.select(condition,value)\n",
    "    #####\n",
    "    #####\n",
    "\n",
    "    condition = [  data.Bangunan == \"Bagus\",\n",
    "                 data.Bangunan == \"Sedang\",\n",
    "\n",
    "    ]\n",
    "\n",
    "    value = [2,1]\n",
    "\n",
    "    data.Bangunan = np.select(condition,value,0)\n",
    "\n",
    "\n",
    "    condition = [ \n",
    "                data.Peruntukan == \"Pasar\",\n",
    "                 data.Peruntukan == \"Kantor\",\n",
    "                 data.Peruntukan == \"Ruko\",\n",
    "                 data.Peruntukan == \"Taman\",\n",
    "                 data.Peruntukan == \"Perumahan\",\n",
    "                 data.Peruntukan == \"Sawah\",\n",
    "\n",
    "    ]\n",
    "\n",
    "    value = [5,4,3,2,1,0]\n",
    "\n",
    "    data.Peruntukan = np.select(condition,value,0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38057e5c",
   "metadata": {},
   "source": [
    "# Dataframe to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a60108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=False, batch_size=4):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('Peruntukan')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e24a5",
   "metadata": {},
   "source": [
    "# Feature Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9a634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "  normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8498ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_features(train_ds):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "\n",
    "    # Numerical features.\n",
    "    for header in [\"Jarak_pusat_kota2\",\"Visibilitas\",\"Bangunan\",\"Luas\"]:\n",
    "      numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "      normalization_layer = get_normalization_layer(header, train_ds)\n",
    "      encoded_numeric_col = normalization_layer(numeric_col)\n",
    "      all_inputs.append(numeric_col)\n",
    "      encoded_features.append(encoded_numeric_col)\n",
    "    return encoded_features, all_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a73e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b25bac",
   "metadata": {},
   "source": [
    "# Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b2e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(encoded_features,all_inputs):\n",
    "    \n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = tf.keras.layers.Dense(6)(x)\n",
    "\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=\"accuracy\",\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8b046",
   "metadata": {},
   "source": [
    "# History build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d84779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history(model,callbacks,train_ds,val_ds):\n",
    "    \n",
    "\n",
    "    history = model.fit(train_ds, epochs=150, validation_data=val_ds, callbacks=callbacks)\n",
    "\n",
    "    # Get the training and validation metrics from the history\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.plot(train_accuracy, label='Training Accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    max_test_accuracy_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "\n",
    "    # Get the corresponding training accuracy\n",
    "    training_accuracy = history.history['accuracy'][max_test_accuracy_index]\n",
    "\n",
    "    print('Best validation accuracy:', max(history.history['val_accuracy']))\n",
    "    print('Training accuracy at the best test accuracy:', training_accuracy)\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a8db84",
   "metadata": {},
   "source": [
    "# Evaluation the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f132b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(ratio,callbacks):\n",
    "    \n",
    "    #split data\n",
    "    training, test_2 = get_data_with_ratio(ratio)\n",
    "    \n",
    "    #change data to number\n",
    "    training = change_categorical_to_number(training)\n",
    "    test = change_categorical_to_number(test_2)\n",
    "    \n",
    "    #df to ds\n",
    "    \n",
    "    train_ds = df_to_dataset(training)\n",
    "    val_ds = df_to_dataset(test)\n",
    "    \n",
    "    #encoded features\n",
    "    \n",
    "    encoded,inputs = encoded_features(train_ds)\n",
    "\n",
    "    \n",
    "    #set the model\n",
    "    model_engine = model(encoded,inputs)\n",
    "    \n",
    "    #run and evaluate the model\n",
    "    model_engine2 = history(model_engine,callbacks,train_ds,val_ds)\n",
    "    \n",
    "    #evaluate confusion matrix\n",
    "    confussion_matrix(model_engine2,val_ds,test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd320d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confussion_matrix(best_model, val_ds, test_data):\n",
    "    from sklearn.metrics import confusion_matrix   \n",
    "    model = best_model\n",
    "    \n",
    "    y_pred = model.model.predict(val_ds)\n",
    "\n",
    "    # Ubah output prediksi menjadi label kelas\n",
    "    label_kelas = [0, 1, 2, 3, 4, 5]\n",
    "    y_pred_label = [label_kelas[np.argmax(prediksi)] for prediksi in y_pred]\n",
    "\n",
    "    # Test labels\n",
    "    test_labels = test_data.Peruntukan\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(test_labels, y_pred_label)\n",
    "    \n",
    "    val_accuracy = model.history['val_accuracy']\n",
    "    train_accuracy = model.history['accuracy']\n",
    "\n",
    "    # Find the index where validation accuracy is highest\n",
    "    max_val_accuracy_index = np.argmax(val_accuracy)\n",
    "\n",
    "    # Find the index of the closest training accuracy to the maximum validation accuracy\n",
    "    closest_train_accuracy_index = np.argmin([abs(i - max_val_accuracy_index) for i in range(len(train_accuracy))])\n",
    "\n",
    "    print('Best validation accuracy:', val_accuracy[max_val_accuracy_index])\n",
    "    print('Closest training accuracy to the maximum validation accuracy:', train_accuracy[closest_train_accuracy_index])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)\n",
    "    \n",
    "    confusion_matrix = cm\n",
    "    \n",
    "    true_positives = np.diagonal(confusion_matrix)\n",
    "\n",
    "    # Step 3: Calculate the accuracy percentage for each class\n",
    "    class_data_totals = np.sum(confusion_matrix, axis=0)\n",
    "    class_accuracies = true_positives / class_data_totals * 100\n",
    "\n",
    "    # Step 4: Calculate the overall accuracy percentage\n",
    "    total_instances = np.sum(confusion_matrix)\n",
    "    overall_accuracy = np.sum(true_positives) / total_instances * 100\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    true_positives = np.diagonal(confusion_matrix)\n",
    "    false_positives = np.sum(confusion_matrix, axis=0) - true_positives\n",
    "    false_negatives = np.sum(confusion_matrix, axis=1) - true_positives\n",
    "\n",
    "    # Step 3: Calculate precision, recall, and F1 score for each label\n",
    "    accuracy = true_positives / np.sum(confusion_matrix, axis=1)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Step 4: Calculate the total accuracy\n",
    "    total_accuracy = np.sum(true_positives) / np.sum(confusion_matrix) * 100\n",
    "    total_precision = np.mean(precision)\n",
    "    total_recall = np.mean(recall)\n",
    "    total_f1 = np.mean(f1_score)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Total Accuracy:\", total_accuracy)\n",
    "    print(\"Total Precision:\", total_precision)\n",
    "    print(\"Total Recall:\", total_recall)\n",
    "    \n",
    "    print(\"TP for each label\", true_positives)\n",
    "    print(\"Total data for each label\",  np.sum(confusion_matrix, axis=1))\n",
    "    print(\"FP for each label\", np.sum(confusion_matrix, axis=0) - true_positives)\n",
    "    print(\"FN for each label\", np.sum(confusion_matrix, axis=1) - true_positives)\n",
    "    # Print the results\n",
    "    print(\"Accuracy for each label:\", class_accuracies)\n",
    "    print(\"Precision for each label:\", precision)\n",
    "    print(\"Recall for each label:\", recall)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fecd5a3",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de9978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd072430",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_1 = ModelCheckpoint(\"50.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "ratio_1 = 0.5\n",
    "\n",
    "callback_2= ModelCheckpoint(\"40.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "ratio_2 = 0.4\n",
    "\n",
    "callback_3= ModelCheckpoint(\"30.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "ratio_3 = 0.3\n",
    "\n",
    "callback_4= ModelCheckpoint(\"20.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "ratio_4 = 0.2\n",
    "\n",
    "callback_5= ModelCheckpoint(\"10.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "ratio_5 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f349cb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569585/2235196391.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data.append(label_train)\n",
      "/tmp/ipykernel_569585/2235196391.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_data.append(label_test)\n",
      "/tmp/ipykernel_569585/2235196391.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data.append(label_train)\n",
      "/tmp/ipykernel_569585/2235196391.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_data.append(label_test)\n",
      "/tmp/ipykernel_569585/2235196391.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data.append(label_train)\n",
      "/tmp/ipykernel_569585/2235196391.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_data.append(label_test)\n",
      "/tmp/ipykernel_569585/2235196391.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data.append(label_train)\n",
      "/tmp/ipykernel_569585/2235196391.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_data.append(label_test)\n",
      "/tmp/ipykernel_569585/2235196391.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data.append(label_train)\n",
      "/tmp/ipykernel_569585/2235196391.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_data.append(label_test)\n",
      "/tmp/ipykernel_569585/2235196391.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data.append(label_train)\n",
      "/tmp/ipykernel_569585/2235196391.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_data.append(label_test)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Visibilitas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratio_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(ratio, callbacks)\u001b[0m\n\u001b[1;32m      4\u001b[0m training, test_2 \u001b[38;5;241m=\u001b[39m get_data_with_ratio(ratio)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#change data to number\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mchange_categorical_to_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m test \u001b[38;5;241m=\u001b[39m change_categorical_to_number(test_2)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#df to ds\u001b[39;00m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mchange_categorical_to_number\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m####\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m####\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m condition \u001b[38;5;241m=\u001b[39m [  \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVisibilitas\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrategis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m              data\u001b[38;5;241m.\u001b[39mVisibilitas \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSedang\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m               data\u001b[38;5;241m.\u001b[39mVisibilitas \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKurang\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     14\u001b[0m value \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m data\u001b[38;5;241m.\u001b[39mVisibilitas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mselect(condition,value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Visibilitas'"
     ]
    }
   ],
   "source": [
    "run_model(ratio_1, callback_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1fef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(ratio_2, callback_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c22601",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(ratio_3, callback_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(ratio_4, callback_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f889158",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(ratio_5, callback_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd9982",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f976c7",
   "metadata": {},
   "source": [
    "# Print the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57767fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test_2 = get_data_with_ratio(0.5)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "\n",
    "    \n",
    "    #change data to number\n",
    "training = change_categorical_to_number(training)\n",
    "test = change_categorical_to_number(test_2)\n",
    "\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = df_to_dataset(training)\n",
    "val_ds = df_to_dataset(test)\n",
    "    \n",
    "    #encoded features\n",
    "dataset = train_ds  # Your dataset here\n",
    "\n",
    "# Create an iterator for the dataset\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Get the next element from the iterator\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Create a TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            # Fetch and print the next element from the dataset\n",
    "            element = sess.run(next_element)\n",
    "            print(element)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        # This exception will be raised when all elements have been iterated through\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_ds  # Your dataset here\n",
    "\n",
    "# Create an iterator for the dataset\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Get the next element from the iterator\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Create a TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            # Fetch and print the next element from the dataset\n",
    "            element = sess.run(next_element)\n",
    "            print(element)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        # This exception will be raised when all elements have been iterated through\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea178a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded,inputs = encoded_features(train_ds)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695dc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d353d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
